{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbc3e4f5",
   "metadata": {},
   "source": [
    "LINKS TO DATASETS:\n",
    "**weather**: https://www.kaggle.com/datasets/guillemservera/global-daily-climate-data\n",
    "\n",
    "**flight delay**:https://www.kaggle.com/datasets/arvindnagaonkar/flight-delay?select=Flight_Delay.parquet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406f64f5",
   "metadata": {},
   "source": [
    "# Metadata for Flight Delays Dataset\n",
    "\n",
    "## Metadata\n",
    "\n",
    "| Column                   | Description                                                                    |\n",
    "|--------------------------|--------------------------------------------------------------------------------|\n",
    "| year                     | Year                                                                           |\n",
    "| quarter                  | Quarter of the year                                                            |\n",
    "| day_of_month             | Day of the month                                                               |\n",
    "| day_of_week              | Day of the week                                                                |\n",
    "| flight_date              | Date of the flight                                                             |\n",
    "| marketing_airline_network| Unique Marketing Carrier Code                                                  |\n",
    "| origin_city_name         | Origin Airport, City Name                                                      |\n",
    "| dest_city_name           | Destination Airport, City Name                                                 |\n",
    "| crs_dep_time             | Scheduled Departure Time (local time: hhmm)                                    |\n",
    "| dep_time                 | Actual Departure Time (local time: hhmm)                                       |\n",
    "| dep_delay                | Difference in minutes between scheduled and actual departure time               |\n",
    "| dep_delay_minutes        | Difference in minutes between scheduled and actual departure time (early departures set to 0) |\n",
    "| taxi_out                 | Taxi Out Time (duration from gate to runway) in Minutes                        |\n",
    "| wheels_off               | Wheels-Off Time (local time: hhmm)                                             |\n",
    "| wheels_on                | Wheels-On Time (local time: hhmm)                                              |\n",
    "| taxi_in                  | Taxi In Time (duration from runway to gate) in Minutes                         |\n",
    "| crs_arr_time             | Scheduled Arrival Time (local time: hhmm)                                      |\n",
    "| arr_time                 | Actual Arrival Time (local time: hhmm)                                         |\n",
    "| arr_delay                | Difference in minutes between scheduled and actual arrival time                 |\n",
    "| arr_delay_minutes        | Difference in minutes between scheduled and actual arrival time (early arrivals set to 0) |\n",
    "| crs_elapsed_time         | Scheduled Elapsed Time of Flight in Minutes                                    |\n",
    "| actual_elapsed_time      | Elapsed Time of Flight in Minutes                                              |\n",
    "| air_time                 | Flight Time in Minutes                                                         |\n",
    "| distance                 | Distance between airports (miles)                                              |\n",
    "| distance_group           | Distance Intervals (every 250 miles) for Flight Segment                        |\n",
    "| carrier_delay            | Carrier Delay in Minutes                                                       |\n",
    "| weather_delay            | Weather Delay in Minutes                                                       |\n",
    "| nas_delay                | National Air System Delay in Minutes                                           |\n",
    "| security_delay           | Security Delay in Minutes                                                      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb97faef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in c:\\users\\steve\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging in c:\\users\\steve\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kagglehub) (25.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\steve\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\steve\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kagglehub) (2.32.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\steve\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\steve\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->kagglehub) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\steve\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\steve\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->kagglehub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\steve\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->kagglehub) (2025.8.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\steve\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   ---------------------------------------- 2/2 [openpyxl]\n",
      "\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub\n",
    "!pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "950e19ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "#weather_path = kagglehub.dataset_download(\"selfishgene/historical-hourly-weather-data\")\n",
    "weather_path = kagglehub.dataset_download(\"guillemservera/global-daily-climate-data\")\n",
    "flight_path = kagglehub.dataset_download(\"arvindnagaonkar/flight-delay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "360d8138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather dataset path: C:\\Users\\steve\\.cache\\kagglehub\\datasets\\guillemservera\\global-daily-climate-data\\versions\\20\n",
      "Flight delay dataset path: C:\\Users\\steve\\.cache\\kagglehub\\datasets\\arvindnagaonkar\\flight-delay\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "print(\"Weather dataset path:\", weather_path)\n",
    "print(\"Flight delay dataset path:\", flight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96737971",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load weather data (city attributes + example weather features)\n",
    "import pandas as pd\n",
    "\n",
    "city_df = pd.read_csv(f\"{weather_path}/cities.csv\")\n",
    "countries_df = pd.read_csv(f\"{weather_path}/countries.csv\")\n",
    "daily_weather_df = pd.read_parquet(f\"{weather_path}/daily_weather.parquet\")\n",
    "#weatherDescription_df = pd.read_csv(f\"{weather_path}/weather_description.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "894b5fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load flight delay data (.parquet format).\n",
    "# Select columns needed for integration and modeling (so that we dont use too much memory)\n",
    "columns_needed = [\n",
    "    'FlightDate', 'OriginCityName', 'DestCityName',\n",
    "    'CRSDepTime', 'DepTime', 'DepDelayMinutes',\n",
    "    'WeatherDelay', 'Distance', 'ArrDelayMinutes'\n",
    "]\n",
    "\n",
    "flight_df = pd.read_parquet(f\"{flight_path}/Flight_Delay.parquet\", columns=columns_needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35b2396d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City attributes columns: Index(['station_id', 'city_name', 'country', 'state', 'iso2', 'iso3',\n",
      "       'latitude', 'longitude'],\n",
      "      dtype='object')\n",
      "Countries columns: Index(['country', 'native_name', 'iso2', 'iso3', 'population', 'area',\n",
      "       'capital', 'capital_lat', 'capital_lng', 'region', 'continent'],\n",
      "      dtype='object')\n",
      "Weather Description columns: Index(['station_id', 'city_name', 'date', 'season', 'avg_temp_c', 'min_temp_c',\n",
      "       'max_temp_c', 'precipitation_mm', 'snow_depth_mm', 'avg_wind_dir_deg',\n",
      "       'avg_wind_speed_kmh', 'peak_wind_gust_kmh', 'avg_sea_level_pres_hpa',\n",
      "       'sunshine_total_min'],\n",
      "      dtype='object')\n",
      "Flight delay columns: Index(['FlightDate', 'OriginCityName', 'DestCityName', 'CRSDepTime', 'DepTime',\n",
      "       'DepDelayMinutes', 'WeatherDelay', 'Distance', 'ArrDelayMinutes'],\n",
      "      dtype='object')\n",
      "   FlightDate OriginCityName    DestCityName  CRSDepTime  DepTime  \\\n",
      "1  2018-01-15     Newark, NJ  Charleston, SC        1845   1928.0   \n",
      "2  2018-01-16     Newark, NJ  Charleston, SC        1835   1956.0   \n",
      "3  2018-01-17     Newark, NJ  Charleston, SC        1835   1836.0   \n",
      "4  2018-01-18     Newark, NJ  Charleston, SC        1845   1844.0   \n",
      "6  2018-01-20     Newark, NJ  Charleston, SC        1835   1829.0   \n",
      "\n",
      "   DepDelayMinutes  WeatherDelay  Distance  ArrDelayMinutes  \n",
      "1             43.0           0.0     628.0             41.0  \n",
      "2             81.0           0.0     628.0             69.0  \n",
      "3              1.0           0.0     628.0              0.0  \n",
      "4              0.0           0.0     628.0              0.0  \n",
      "6              0.0           0.0     628.0              0.0  \n"
     ]
    }
   ],
   "source": [
    "#see what columns the datasets have\n",
    "print(\"City attributes columns:\", city_df.columns)\n",
    "print(\"Countries columns:\", countries_df.columns)\n",
    "print(\"Weather Description columns:\",daily_weather_df.columns)\n",
    "print(\"Flight delay columns:\", flight_df.columns)\n",
    "print(flight_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed6b9bd",
   "metadata": {},
   "source": [
    "# Part C: Data Integration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92cb2315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next step is to start cleaning and preparing the data\n",
    "\n",
    "#clean city names for better matching\n",
    "flight_df['OriginCityName_clean'] = flight_df['OriginCityName'].str.extract(r'^(.*?)(?:,|$)', expand=False).str.strip().str.lower()\n",
    "daily_weather_df['city_name_clean'] = daily_weather_df['city_name'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f88dbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FlightDate OriginCityName    DestCityName  CRSDepTime  DepTime  \\\n",
      "1 2018-01-15     Newark, NJ  Charleston, SC        1845   1928.0   \n",
      "2 2018-01-16     Newark, NJ  Charleston, SC        1835   1956.0   \n",
      "3 2018-01-17     Newark, NJ  Charleston, SC        1835   1836.0   \n",
      "4 2018-01-18     Newark, NJ  Charleston, SC        1845   1844.0   \n",
      "6 2018-01-20     Newark, NJ  Charleston, SC        1835   1829.0   \n",
      "\n",
      "   DepDelayMinutes  WeatherDelay  Distance  ArrDelayMinutes  \\\n",
      "1             43.0           0.0     628.0             41.0   \n",
      "2             81.0           0.0     628.0             69.0   \n",
      "3              1.0           0.0     628.0              0.0   \n",
      "4              0.0           0.0     628.0              0.0   \n",
      "6              0.0           0.0     628.0              0.0   \n",
      "\n",
      "  OriginCityName_clean  \n",
      "1               newark  \n",
      "2               newark  \n",
      "3               newark  \n",
      "4               newark  \n",
      "6               newark  \n",
      "  station_id city_name       date  season  avg_temp_c  min_temp_c  max_temp_c  \\\n",
      "0      41515  Asadabad 1957-07-01  Summer        27.0        21.1        35.6   \n",
      "1      41515  Asadabad 1957-07-02  Summer        22.8        18.9        32.2   \n",
      "2      41515  Asadabad 1957-07-03  Summer        24.3        16.7        35.6   \n",
      "3      41515  Asadabad 1957-07-04  Summer        26.6        16.1        37.8   \n",
      "4      41515  Asadabad 1957-07-05  Summer        30.8        20.0        41.7   \n",
      "\n",
      "   precipitation_mm  snow_depth_mm  avg_wind_dir_deg  avg_wind_speed_kmh  \\\n",
      "0               0.0            NaN               NaN                 NaN   \n",
      "1               0.0            NaN               NaN                 NaN   \n",
      "2               1.0            NaN               NaN                 NaN   \n",
      "3               4.1            NaN               NaN                 NaN   \n",
      "4               0.0            NaN               NaN                 NaN   \n",
      "\n",
      "   peak_wind_gust_kmh  avg_sea_level_pres_hpa  sunshine_total_min  \\\n",
      "0                 NaN                     NaN                 NaN   \n",
      "1                 NaN                     NaN                 NaN   \n",
      "2                 NaN                     NaN                 NaN   \n",
      "3                 NaN                     NaN                 NaN   \n",
      "4                 NaN                     NaN                 NaN   \n",
      "\n",
      "  city_name_clean  \n",
      "0        asadabad  \n",
      "1        asadabad  \n",
      "2        asadabad  \n",
      "3        asadabad  \n",
      "4        asadabad  \n"
     ]
    }
   ],
   "source": [
    "#convert Flight Date and Weather Date to Datetime\n",
    "\n",
    "flight_df['FlightDate'] = pd.to_datetime(flight_df['FlightDate'])\n",
    "daily_weather_df['date'] = pd.to_datetime(daily_weather_df['date'])\n",
    "\n",
    "print(flight_df.head())\n",
    "print(daily_weather_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdab93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original flight data shape: (30132672, 10)\n",
      "After merging with weather data: (30250045, 25)\n",
      "\n",
      "Successful weather matches: 7952755 out of 30250045 flights\n",
      "\n",
      "Sample of merged data:\n",
      "  FlightDate OriginCityName  avg_temp_c  precipitation_mm  avg_wind_speed_kmh  \\\n",
      "0 2018-01-15     Newark, NJ         NaN               NaN                 NaN   \n",
      "1 2018-01-16     Newark, NJ         NaN               NaN                 NaN   \n",
      "2 2018-01-17     Newark, NJ         NaN               NaN                 NaN   \n",
      "3 2018-01-18     Newark, NJ         NaN               NaN                 NaN   \n",
      "4 2018-01-20     Newark, NJ         NaN               NaN                 NaN   \n",
      "5 2018-01-21     Newark, NJ         NaN               NaN                 NaN   \n",
      "6 2018-01-22     Newark, NJ         NaN               NaN                 NaN   \n",
      "7 2018-01-23     Newark, NJ         NaN               NaN                 NaN   \n",
      "8 2018-01-25     Newark, NJ         NaN               NaN                 NaN   \n",
      "9 2018-01-26     Newark, NJ         NaN               NaN                 NaN   \n",
      "\n",
      "   DepDelayMinutes  \n",
      "0             43.0  \n",
      "1             81.0  \n",
      "2              1.0  \n",
      "3              0.0  \n",
      "4              0.0  \n",
      "5              0.0  \n",
      "6              2.0  \n",
      "7              0.0  \n",
      "8              0.0  \n",
      "9              0.0  \n"
     ]
    }
   ],
   "source": [
    "#merge flight data with weather data for origin cities\n",
    "#match on city name and date\n",
    "merged_df = flight_df.merge(\n",
    "    daily_weather_df,\n",
    "    left_on=['OriginCityName_clean', 'FlightDate'],\n",
    "    right_on=['city_name_clean', 'date'],\n",
    "    how='left',\n",
    "    suffixes=('', '_origin_weather')\n",
    ")\n",
    "\n",
    "print(f\"Original flight data shape: {flight_df.shape}\")\n",
    "print(f\"After merging with weather data: {merged_df.shape}\")\n",
    "print(f\"\\nSuccessful weather matches: {merged_df['avg_temp_c'].notna().sum()} out of {len(merged_df)} flights\")\n",
    "print(\"\\nSample of merged data:\")\n",
    "print(merged_df[['FlightDate', 'OriginCityName', 'avg_temp_c', 'precipitation_mm', 'avg_wind_speed_kmh', 'DepDelayMinutes']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e66c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export orirginal merged df to excel\n",
    "merged_df.to_csv('merged_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703ba28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Integration Statistics ===\n",
      "\n",
      "Total flights: 30,250,045\n",
      "Flights with weather data: 8,099,227\n",
      "Match rate: 26.77%\n",
      "Flights without weather data: 22,150,818\n",
      "\n",
      "Top 10 cities by weather data coverage:\n",
      "                 with_weather  total_flights  match_rate\n",
      "OriginCityName                                          \n",
      "Des Moines, IA          69088          69088       100.0\n",
      "CONCORD, NC              1126           1126       100.0\n",
      "Austin, TX             284749         284749       100.0\n",
      "Harrisburg, PA          41820          41820       100.0\n",
      "Columbia, MO             9675           9675       100.0\n",
      "Santa Rosa, CA          15783          15783       100.0\n",
      "Columbia, SC            39503          39503       100.0\n",
      "Columbus, GA             6262           6262       100.0\n",
      "Tallahassee, FL         24070          24070       100.0\n",
      "Columbus, MS             4895           4895       100.0\n",
      "\n",
      "Bottom 10 cities by weather data coverage:\n",
      "                                with_weather  total_flights  match_rate\n",
      "OriginCityName                                                         \n",
      "Butte, MT                                  0           3009         0.0\n",
      "Allentown/Bethlehem/Easton, PA             0          23749         0.0\n",
      "Cape Girardeau, MO                         0           2826         0.0\n",
      "Casper, WY                                 0           8508         0.0\n",
      "Cedar City, UT                             0           2846         0.0\n",
      "Cedar Rapids/Iowa City, IA                 0          39403         0.0\n",
      "Champaign/Urbana, IL                       0           9402         0.0\n",
      "Alpena, MI                                 0           2854         0.0\n",
      "Charleston/Dunbar, WV                      0          18143         0.0\n",
      "Wenatchee, WA                              0           3325         0.0\n"
     ]
    }
   ],
   "source": [
    "#check integration quality and coverage\n",
    "print(\"=== Data Integration Statistics ===\\n\")\n",
    "\n",
    "#count matched vs unmatched records\n",
    "matched = merged_df['station_id'].notna().sum()\n",
    "total = len(merged_df)\n",
    "match_rate = (matched / total) * 100\n",
    "\n",
    "print(f\"Total flights: {total:,}\")\n",
    "print(f\"Flights with weather data: {matched:,}\")\n",
    "print(f\"Match rate: {match_rate:.2f}%\")\n",
    "print(f\"Flights without weather data: {total - matched:,}\\n\")\n",
    "\n",
    "#check which cities have the best coverage\n",
    "city_coverage = merged_df.groupby('OriginCityName').agg({\n",
    "    'station_id': lambda x: x.notna().sum(),\n",
    "    'FlightDate': 'count'\n",
    "}).rename(columns={'station_id': 'with_weather', 'FlightDate': 'total_flights'})\n",
    "city_coverage['match_rate'] = (city_coverage['with_weather'] / city_coverage['total_flights'] * 100).round(2)\n",
    "city_coverage = city_coverage.sort_values('match_rate', ascending=False)\n",
    "\n",
    "print(\"Top 10 cities by weather data coverage:\")\n",
    "print(city_coverage.head(10))\n",
    "print(\"\\nBottom 10 cities by weather data coverage:\")\n",
    "print(city_coverage.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11a586e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Examples of Data Integration Cases ===\n",
      "\n",
      "Example 1: Flights WITH weather data\n",
      "    FlightDate  OriginCityName  DepDelayMinutes  avg_temp_c  precipitation_mm  \\\n",
      "15  2018-01-07  Providence, RI              0.0       -14.6               0.0   \n",
      "299 2018-01-02  Des Moines, IA             27.0       -20.5               0.0   \n",
      "300 2018-01-06  Des Moines, IA             10.0       -15.7               0.0   \n",
      "\n",
      "     avg_wind_speed_kmh  \n",
      "15                 15.1  \n",
      "299                19.8  \n",
      "300                15.8  \n",
      "\n",
      "======================================================================\n",
      "\n",
      "Example 2: Flights WITHOUT weather data (no match found)\n",
      "  FlightDate OriginCityName  DepDelayMinutes  avg_temp_c  precipitation_mm\n",
      "0 2018-01-15     Newark, NJ             43.0         NaN               NaN\n",
      "1 2018-01-16     Newark, NJ             81.0         NaN               NaN\n",
      "2 2018-01-17     Newark, NJ              1.0         NaN               NaN\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Example 3: Flights on high precipitation days (>10mm)\n",
      "    FlightDate OriginCityName  DepDelayMinutes  WeatherDelay  \\\n",
      "573 2018-01-12    Atlanta, GA              0.0           0.0   \n",
      "586 2018-01-28    Atlanta, GA              0.0           0.0   \n",
      "622 2018-01-12   Richmond, VA              8.0           0.0   \n",
      "\n",
      "     precipitation_mm  avg_wind_speed_kmh  \n",
      "573              13.2                20.5  \n",
      "586              34.3                10.8  \n",
      "622              25.4                20.9  \n"
     ]
    }
   ],
   "source": [
    "#specific examples of integrated data\n",
    "print(\"=== Examples of Data Integration Cases ===\\n\")\n",
    "\n",
    "#Example 1: Successful integration\n",
    "print(\"Example 1: Flights WITH weather data\")\n",
    "example_with_weather = merged_df[merged_df['avg_temp_c'].notna()].head(3)\n",
    "print(example_with_weather[['FlightDate', 'OriginCityName', 'DepDelayMinutes', \n",
    "                             'avg_temp_c', 'precipitation_mm', 'avg_wind_speed_kmh']])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "#Example 2: Failed integration\n",
    "print(\"Example 2: Flights WITHOUT weather data (no match found)\")\n",
    "example_without_weather = merged_df[merged_df['avg_temp_c'].isna()].head(3)\n",
    "print(example_without_weather[['FlightDate', 'OriginCityName', 'DepDelayMinutes', \n",
    "                                'avg_temp_c', 'precipitation_mm']])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "#Example 3: High precipitation days\n",
    "print(\"Example 3: Flights on high precipitation days (>10mm)\")\n",
    "high_precip = merged_df[merged_df['precipitation_mm'] > 10].head(3)\n",
    "print(high_precip[['FlightDate', 'OriginCityName', 'DepDelayMinutes', \n",
    "                    'WeatherDelay', 'precipitation_mm', 'avg_wind_speed_kmh']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ddd2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Functional Dependencies Analysis ===\n",
      "\n",
      "Dependency 1: FlightDate + OriginCity → Weather Conditions\n",
      "If we know the date and origin city, we can determine weather conditions.\n",
      "                                 avg_temp_c  precipitation_mm  \\\n",
      "FlightDate OriginCityName_clean                                 \n",
      "2018-01-01 albany                     -17.3               0.0   \n",
      "           atlanta                     -4.1               0.0   \n",
      "           austin                      -2.3               0.0   \n",
      "           boise                       -3.3               0.0   \n",
      "           boston                     -14.7               0.0   \n",
      "\n",
      "                                 avg_wind_speed_kmh  \n",
      "FlightDate OriginCityName_clean                      \n",
      "2018-01-01 albany                               8.6  \n",
      "           atlanta                             21.2  \n",
      "           austin                              12.2  \n",
      "           boise                                4.3  \n",
      "           boston                              26.3  \n",
      "\n",
      "\n",
      "Dependency 2: OriginCity + DestinationCity → Distance\n",
      "If we know origin and destination, distance is fixed.\n",
      "                                       Distance  Unique_Values  Flight_Count\n",
      "OriginCityName  DestCityName                                                \n",
      "Aberdeen, SD    Minneapolis, MN           257.0              1          3368\n",
      "Abilene, TX     Dallas/Fort Worth, TX     158.0              1          8100\n",
      "                Houston, TX               307.0              1           543\n",
      "Adak Island, AK Anchorage, AK            1192.0              1           338\n",
      "                Cold Bay, AK              616.0              1            94\n",
      "Verification: Each route has 4 unique distance value (should be 1)\n",
      "\n",
      "\n",
      "Dependency 3: Relationship between Weather Conditions and Weather Delay\n",
      "Poor weather conditions may correlate with weather delays.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_31888\\1652483931.py:27: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  weather_impact = merged_df[merged_df['precipitation_mm'].notna()].groupby(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Avg_Weather_Delay  Avg_Departure_Delay  Flight_Count\n",
      "precipitation_mm                                                      \n",
      "None/Light                 0.780456            15.139806        645152\n",
      "Light                      1.247871            17.358439        691022\n",
      "Moderate                   1.462657            18.703186        370212\n",
      "Heavy                      2.879042            23.474611        604649\n"
     ]
    }
   ],
   "source": [
    "#Analyze functional dependencies\n",
    "print(\"=== Functional Dependencies Analysis ===\\n\")\n",
    "\n",
    "#1. FlightDate + OriginCity -> Weather conditions\n",
    "print(\"Dependency 1: FlightDate + OriginCity → Weather Conditions\")\n",
    "print(\"If we know the date and origin city, we can determine weather conditions.\")\n",
    "sample_dep1 = merged_df[merged_df['avg_temp_c'].notna()].groupby(['FlightDate', 'OriginCityName_clean']).agg({\n",
    "    'avg_temp_c': 'first',\n",
    "    'precipitation_mm': 'first',\n",
    "    'avg_wind_speed_kmh': 'first'\n",
    "}).head(5)\n",
    "print(sample_dep1)\n",
    "print()\n",
    "\n",
    "#2. Distance dependency\n",
    "print(\"\\nDependency 2: OriginCity + DestinationCity → Distance\")\n",
    "print(\"If we know origin and destination, distance is fixed.\")\n",
    "sample_dep2 = merged_df.groupby(['OriginCityName', 'DestCityName'])['Distance'].agg(['first', 'nunique', 'count'])\n",
    "sample_dep2.columns = ['Distance', 'Unique_Values', 'Flight_Count']\n",
    "print(sample_dep2.head())\n",
    "print(f\"Verification: Each route has {sample_dep2['Unique_Values'].max()} unique distance value (should be 1)\")\n",
    "print()\n",
    "\n",
    "#3. Weather delay dependency\n",
    "print(\"\\nDependency 3: Relationship between Weather Conditions and Weather Delay\")\n",
    "print(\"Poor weather conditions may correlate with weather delays.\")\n",
    "weather_impact = merged_df[merged_df['precipitation_mm'].notna()].groupby(\n",
    "    pd.cut(merged_df['precipitation_mm'], bins=[0, 1, 5, 10, 100], labels=['None/Light', 'Light', 'Moderate', 'Heavy'])\n",
    ").agg({\n",
    "    'WeatherDelay': 'mean',\n",
    "    'DepDelayMinutes': 'mean',\n",
    "    'FlightDate': 'count'\n",
    "})\n",
    "weather_impact.columns = ['Avg_Weather_Delay', 'Avg_Departure_Delay', 'Flight_Count']\n",
    "print(weather_impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd80973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Temporal Integration Patterns ===\n",
      "\n",
      "Weather data coverage by month:\n",
      "       Weather_Coverage_%\n",
      "Month                    \n",
      "1                   26.77\n",
      "2                   26.71\n",
      "3                   26.73\n",
      "4                   26.90\n",
      "5                   26.61\n",
      "6                   26.57\n",
      "7                   26.64\n",
      "8                   26.84\n",
      "9                   26.95\n",
      "10                  26.92\n",
      "11                  26.91\n",
      "12                  26.74\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Correlation between weather features and delays:\n",
      "                    DepDelayMinutes  WeatherDelay\n",
      "WeatherDelay               0.306218      1.000000\n",
      "ArrDelayMinutes            0.981775      0.313277\n",
      "DepDelayMinutes            1.000000      0.306218\n",
      "precipitation_mm           0.064809      0.048897\n",
      "avg_wind_speed_kmh         0.027882      0.014568\n",
      "avg_temp_c                -0.000038     -0.007116\n"
     ]
    }
   ],
   "source": [
    "#temp patterns\n",
    "print(\"=== Temporal Integration Patterns ===\\n\")\n",
    "\n",
    "#monthly coverage\n",
    "merged_df['Month'] = merged_df['FlightDate'].dt.month\n",
    "monthly_coverage = merged_df.groupby('Month').agg({\n",
    "    'station_id': lambda x: (x.notna().sum() / len(x) * 100)\n",
    "}).rename(columns={'station_id': 'Weather_Coverage_%'})\n",
    "print(\"Weather data coverage by month:\")\n",
    "print(monthly_coverage.round(2))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "#correlation between weather and delay\n",
    "print(\"Correlation between weather features and delays:\")\n",
    "weather_delay_cols = ['avg_temp_c', 'precipitation_mm', 'avg_wind_speed_kmh', \n",
    "                      'DepDelayMinutes', 'WeatherDelay', 'ArrDelayMinutes']\n",
    "correlation_matrix = merged_df[weather_delay_cols].corr()\n",
    "print(correlation_matrix[['DepDelayMinutes', 'WeatherDelay']].sort_values('WeatherDelay', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26a70e4",
   "metadata": {},
   "source": [
    "# Part D: Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc796ec",
   "metadata": {},
   "source": [
    "## Handle Null Data - Identify Missing Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4080dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Null Data Analysis ===\n",
      "\n",
      "Columns with missing values:\n",
      "                    Column  Null_Count  Null_Percentage\n",
      "23      sunshine_total_min    30248207            99.99\n",
      "21      peak_wind_gust_kmh    30245664            99.99\n",
      "18           snow_depth_mm    23284218            76.97\n",
      "19        avg_wind_dir_deg    22981356            75.97\n",
      "22  avg_sea_level_pres_hpa    22567007            74.60\n",
      "20      avg_wind_speed_kmh    22332980            73.83\n",
      "14              avg_temp_c    22297290            73.71\n",
      "17        precipitation_mm    22215998            73.44\n",
      "16              max_temp_c    22168627            73.28\n",
      "15              min_temp_c    22154523            73.24\n",
      "12                    date    22150818            73.23\n",
      "13                  season    22150818            73.23\n",
      "10              station_id    22150818            73.23\n",
      "11               city_name    22150818            73.23\n",
      "24         city_name_clean    22150818            73.23\n",
      "\n",
      "\n",
      "Missing data in key columns:\n",
      "DepTime                  :       0 ( 0.00%)\n",
      "DepDelayMinutes          :       0 ( 0.00%)\n",
      "WeatherDelay             :       0 ( 0.00%)\n",
      "avg_temp_c               : 22,297,290 (73.71%)\n",
      "precipitation_mm         : 22,215,998 (73.44%)\n",
      "avg_wind_speed_kmh       : 22,332,980 (73.83%)\n",
      "ArrDelayMinutes          :       0 ( 0.00%)\n"
     ]
    }
   ],
   "source": [
    "#analyze null\n",
    "print(\"=== Null Data Analysis ===\\n\")\n",
    "\n",
    "#missing value stats\n",
    "null_stats = pd.DataFrame({\n",
    "    'Column': merged_df.columns,\n",
    "    'Null_Count': merged_df.isnull().sum().values,\n",
    "    'Null_Percentage': (merged_df.isnull().sum().values / len(merged_df) * 100).round(2)\n",
    "})\n",
    "null_stats = null_stats[null_stats['Null_Count'] > 0].sort_values('Null_Percentage', ascending=False)\n",
    "\n",
    "print(\"Columns with missing values:\")\n",
    "print(null_stats)\n",
    "print()\n",
    "\n",
    "\n",
    "key_columns = ['DepTime', 'DepDelayMinutes', 'WeatherDelay', 'avg_temp_c', \n",
    "               'precipitation_mm', 'avg_wind_speed_kmh', 'ArrDelayMinutes']\n",
    "print(\"\\nMissing data in key columns:\")\n",
    "for col in key_columns:\n",
    "    if col in merged_df.columns:\n",
    "        missing = merged_df[col].isnull().sum()\n",
    "        total = len(merged_df)\n",
    "        pct = (missing / total * 100)\n",
    "        print(f\"{col:25s}: {missing:7,} ({pct:5.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
